{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Gwck30apIFr"
      },
      "outputs": [],
      "source": [
        "!pip -q install wget\n",
        "!pip -q install opencv-python"
      ],
      "id": "2Gwck30apIFr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84ac0a31-2d2e-47dc-afa8-503b2e87b6cc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import wget\n",
        "import shutil\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image"
      ],
      "id": "84ac0a31-2d2e-47dc-afa8-503b2e87b6cc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14a90cd8-58a5-4449-8551-e43ba25dc779"
      },
      "source": [
        "If a GPU is available, use it."
      ],
      "id": "14a90cd8-58a5-4449-8551-e43ba25dc779"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b063187c-a4b4-40fe-a9cc-0ca2da6ec06c"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "id": "b063187c-a4b4-40fe-a9cc-0ca2da6ec06c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8d9c154-74f0-4d50-94f5-0b1a555b25a5"
      },
      "source": [
        "Let's take a look at the training data. We have eight columns: image URL, its width and height in pixels, positions of the top-left and bottom-right corners of a bounding box and the question to be answered.\n",
        "\n",
        "We take subset of training data to quickly get acquainted with the task"
      ],
      "id": "f8d9c154-74f0-4d50-94f5-0b1a555b25a5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aca5f15b-0a6f-4b5f-a490-111a5020685c"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train_sample.csv')\n",
        "train.head()"
      ],
      "id": "aca5f15b-0a6f-4b5f-a490-111a5020685c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce4c2ba6-a2a8-40b0-b94c-b23d1b2d4ef6"
      },
      "source": [
        "`image` and `question` are input columns. A human asked this question about some object located in this image. So, our goal is to find this object. In other words, `left`, `top`, `right`, and `bottom` are *target variables* we want to predict."
      ],
      "id": "ce4c2ba6-a2a8-40b0-b94c-b23d1b2d4ef6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db719e38-10a7-4850-acaa-abb746b434b7"
      },
      "source": [
        "Now let's download all the images."
      ],
      "id": "db719e38-10a7-4850-acaa-abb746b434b7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ad1c838-0c08-482a-89c4-4ea1e1d99a11"
      },
      "outputs": [],
      "source": [
        "os.mkdir('imgs')\n",
        "img_paths = Parallel(\n",
        "    n_jobs=100)(delayed(wget.download)(img_url, out='imgs') for img_url in tqdm(train.image)\n",
        ")"
      ],
      "id": "6ad1c838-0c08-482a-89c4-4ea1e1d99a11"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03b0cfcb-fac9-468d-950c-ab8f4fc1316f"
      },
      "source": [
        "We will use the following zero-shot prediction scheme. First, we'll make use of a detection model ([YOLOR](https://github.com/WongKinYiu/yolor)) to generate candidate rectangles. Then, we'll apply [CLIP](https://github.com/openai/CLIP) to measure a similarity between question and part of the image bounded by each candidate rectangle. To make a prediction, we'll use a candidate with highest similarity.\n",
        "\n",
        "Now, let's clone YOLOR and CLIP repositories"
      ],
      "id": "03b0cfcb-fac9-468d-950c-ab8f4fc1316f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd0feea6-71a9-4589-8db4-b7a1da5e092d"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolor\n",
        "!pip -q install ftfy regex\n",
        "!pip -q install git+https://github.com/openai/CLIP.git\n",
        "import clip"
      ],
      "id": "bd0feea6-71a9-4589-8db4-b7a1da5e092d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8LMLZonPFU_"
      },
      "source": [
        "Download [pre-trained weights](https://drive.google.com/file/d/1Tdn3yqpZ79X7R1Ql0zNlNScB1Dv9Fp76/view?usp=sharing)"
      ],
      "id": "e8LMLZonPFU_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4RojL6HPEea"
      },
      "outputs": [],
      "source": [
        "!gdown 1Tdn3yqpZ79X7R1Ql0zNlNScB1Dv9Fp76"
      ],
      "id": "X4RojL6HPEea"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f6fbac4-8831-4d09-87be-a0af042f2e31"
      },
      "source": [
        "We now can generate candidates."
      ],
      "id": "7f6fbac4-8831-4d09-87be-a0af042f2e31"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QIqY0b5NPX9"
      },
      "outputs": [],
      "source": [
        "cd yolor"
      ],
      "id": "-QIqY0b5NPX9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COiZNpUFu7OR"
      },
      "outputs": [],
      "source": [
        "!python detect.py --source ../imgs --cfg cfg/yolor_p6.cfg --weights ../yolor_p6.pt --conf 0.1 --save-txt --img-size 1280 --device 0"
      ],
      "id": "COiZNpUFu7OR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvKGVo_HNQ15"
      },
      "outputs": [],
      "source": [
        "cd .."
      ],
      "id": "cvKGVo_HNQ15"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03f07be7-f587-442a-b3d9-e040bda9c9f6"
      },
      "source": [
        "We use average IoU (Intersection over Union) as a quality metric."
      ],
      "id": "03f07be7-f587-442a-b3d9-e040bda9c9f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb4bb8e0-9195-4d02-952b-ad4937ea9bc1"
      },
      "outputs": [],
      "source": [
        "def get_iou(bb1, bb2):\n",
        "    # Taken from https://stackoverflow.com/a/42874377\n",
        "    \"\"\"\n",
        "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    bb1 : dict\n",
        "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
        "        The (x1, y1) position is at the top left corner,\n",
        "        the (x2, y2) position is at the bottom right corner\n",
        "    bb2 : dict\n",
        "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
        "        The (x, y) position is at the top left corner,\n",
        "        the (x2, y2) position is at the bottom right corner\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        in [0, 1]\n",
        "    \"\"\"\n",
        "    assert bb1['x1'] < bb1['x2']\n",
        "    assert bb1['y1'] < bb1['y2']\n",
        "    assert bb2['x1'] < bb2['x2']\n",
        "    assert bb2['y1'] < bb2['y2']\n",
        "\n",
        "    # determine the coordinates of the intersection rectangle\n",
        "    x_left = max(bb1['x1'], bb2['x1'])\n",
        "    y_top = max(bb1['y1'], bb2['y1'])\n",
        "    x_right = min(bb1['x2'], bb2['x2'])\n",
        "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
        "\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "\n",
        "    # The intersection of two axis-aligned bounding boxes is always an\n",
        "    # axis-aligned bounding box\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "    # compute the area of both AABBs\n",
        "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
        "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
        "\n",
        "    # compute the intersection over union by taking the intersection\n",
        "    # area and dividing it by the sum of prediction + ground-truth\n",
        "    # areas - the interesection area\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou"
      ],
      "id": "bb4bb8e0-9195-4d02-952b-ad4937ea9bc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b52b72e-1511-4dc3-b508-15837c8fa4f8"
      },
      "source": [
        "Let's run a prediction for the train set!"
      ],
      "id": "5b52b72e-1511-4dc3-b508-15837c8fa4f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56248edb-3e36-4eab-a60f-5aad291cf3b5"
      },
      "outputs": [],
      "source": [
        "def process_image(img_path, bb_prediction, preprocess):\n",
        "    np_img = cv2.imread(img_path)\n",
        "    imgs = []\n",
        "    with open(bb_prediction) as f:\n",
        "        lines = f.readlines()\n",
        "    bbs = [list(map(float, line.split(' ')[1:5])) for line in lines]\n",
        "    bbs_processed = []\n",
        "    for bb in bbs:\n",
        "        y, x, h, w = bb\n",
        "        height, width, channels = np_img.shape\n",
        "        x *= height\n",
        "        w *= height\n",
        "        y *= width\n",
        "        h *= width\n",
        "        crop = np_img[int(x - w // 2):int(x + w // 2), int(y - h // 2):int(y + h // 2), :]\n",
        "        imgs.append(preprocess(Image.fromarray(crop)).unsqueeze(0).to(device))\n",
        "        bbs_processed.append({'y1': int(x - w // 2), 'y2': int(x + w // 2), 'x1': int(y - h // 2), 'x2': int(y + h // 2)})\n",
        "    return imgs, bbs_processed\n",
        "\n",
        "def predict(img_url, question, preprocess, model):\n",
        "    img_path = os.path.join('imgs', img_url.split('/')[-1])\n",
        "    bb_prediction = os.path.join('yolor', 'inference', 'output', img_url.split('/')[-1]).replace('.jpg', '.txt')\n",
        "    imgs, bbs_processed = process_image(img_path, bb_prediction, preprocess)\n",
        "    \n",
        "    text = clip.tokenize([question]).to(device)\n",
        "    probs = []\n",
        "    for img in imgs:\n",
        "        with torch.no_grad():\n",
        "            logits_per_image, logits_per_text = model(img, text)\n",
        "            probs.append(logits_per_image.softmax(dim=-1).cpu().numpy()[0][0])\n",
        "    \n",
        "    return bbs_processed[np.argmax(probs)]\n",
        "\n",
        "def draw_prediction(img_url, pred_bb, gt_bb):\n",
        "    img_path = os.path.join('imgs', img_url.split('/')[-1])\n",
        "    img = cv2.imread(img_path)\n",
        "    \n",
        "    result = img.copy()\n",
        "    cv2.rectangle(result, (gt_bb['x1'], gt_bb['y1']), (gt_bb['x2'], gt_bb['y2']), (0, 255, 0), 5)\n",
        "    cv2.rectangle(result, (pred_bb['x1'], pred_bb['y1']), (pred_bb['x2'], pred_bb['y2']), (255, 0, 0), 5)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "id": "56248edb-3e36-4eab-a60f-5aad291cf3b5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dab9d91-a351-4eb0-acf0-85f67531a944"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "n_imgs = 0\n",
        "total_iou = 0.0\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "progress = tqdm(train.iterrows(), total=len(train))\n",
        "for _, row in progress:\n",
        "    img_url = row['image']\n",
        "    question = row['question']\n",
        "    try:\n",
        "        bb_predicted = predict(img_url, question, preprocess, model)\n",
        "    except Exception:\n",
        "        continue\n",
        "    gt_bb = {'x1': row['left'], 'y1': row['top'], 'x2': row['right'], 'y2': row['bottom']}\n",
        "    total_iou += get_iou(gt_bb, bb_predicted)\n",
        "    n_imgs += 1\n",
        "    progress.set_description(f'IoU: {round(total_iou / n_imgs * 100, 2)}')\n",
        "    \n",
        "    left = bb_predicted['x1']\n",
        "    top = bb_predicted['y1']\n",
        "    right = bb_predicted['x2']\n",
        "    bottom = bb_predicted['y2']\n",
        "    predictions.append([img_url, left, top, right, bottom])\n",
        "predictions = pd.DataFrame(predictions, columns=['image', 'left', 'top', 'right', 'bottom'])"
      ],
      "id": "1dab9d91-a351-4eb0-acf0-85f67531a944"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c218ca99-a27a-41aa-b096-bd12920afffc"
      },
      "source": [
        "Let's look at the results."
      ],
      "id": "c218ca99-a27a-41aa-b096-bd12920afffc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjcT5Mh4KjSb"
      },
      "outputs": [],
      "source": [
        "predictions"
      ],
      "id": "XjcT5Mh4KjSb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "151cb6e8-335f-49c8-92a6-cc583d33b6c7"
      },
      "source": [
        "To make a sample submission, we can run"
      ],
      "id": "151cb6e8-335f-49c8-92a6-cc583d33b6c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b62e3ba-88f2-476b-84d6-588e1ab38c23"
      },
      "outputs": [],
      "source": [
        "predictions.to_csv('answer.csv', index=None)"
      ],
      "id": "7b62e3ba-88f2-476b-84d6-588e1ab38c23"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd1d5e82-653f-49ff-ab4c-d3903a2d8d04"
      },
      "source": [
        "That's it! Feel free to use `draw_prediction` function to draw the predicted bounding-box and the ground-truth."
      ],
      "id": "dd1d5e82-653f-49ff-ab4c-d3903a2d8d04"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}