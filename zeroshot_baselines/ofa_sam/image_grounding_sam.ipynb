{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Having answered the questions in textual form, let's draw bounding boxes for obtained object names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image grounding with OFA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download all the necessary tools and models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SQTMm2XrOvme",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQTMm2XrOvme",
    "outputId": "f39f4667-7c79-4f71-d0c0-d57c8a1073f5"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/OFA-Sys/OFA.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bba9c2",
   "metadata": {
    "cellId": "rbhj0lva2om7dxario8we",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31bba9c2",
    "outputId": "437d261c-2967-4f3e-f38c-0a577cca048f"
   },
   "outputs": [],
   "source": [
    "!mkdir -p OFA/checkpoints/\n",
    "!wget https://ofa-silicon.oss-us-west-1.aliyuncs.com/checkpoints/refcocog_large_best.pt\n",
    "!mv refcocog_large_best.pt OFA/checkpoints/refcocog.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76fcaf-c6f2-4395-bd57-5dbe32dcf020",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb76fcaf-c6f2-4395-bd57-5dbe32dcf020",
    "outputId": "ea3311c1-dae3-4525-83cd-4a7da5abda82"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/pytorch/fairseq.git -b v0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WsRUw7MOO4cL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsRUw7MOO4cL",
    "outputId": "a8902ebd-979e-4fdd-a243-c55e11d352ff"
   },
   "outputs": [],
   "source": [
    "cd fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wNEzpz4dO6Go",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNEzpz4dO6Go",
    "outputId": "1dd69926-ba81-464b-ced8-f856e603c9bc"
   },
   "outputs": [],
   "source": [
    "!pip -q install --use-feature=no-binary-enable-wheel-cache ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517de924-9356-4895-8b11-515fd4995307",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "517de924-9356-4895-8b11-515fd4995307",
    "outputId": "beba3d14-e087-487a-e2eb-05958aaa1385"
   },
   "outputs": [],
   "source": [
    "cd ../OFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ACR0QDi4O_z6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACR0QDi4O_z6",
    "outputId": "fcf3b646-fc5a-4e20-a44a-18d9e2f3b193"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!sed '1d' requirements.txt | xargs -I {} pip install {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RgN8t8GRPCZC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgN8t8GRPCZC",
    "outputId": "15285bbc-a3a3-4f22-f1b5-03d5c6db8503"
   },
   "outputs": [],
   "source": [
    "!pip -q install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fairseq import utils, tasks\n",
    "from fairseq import checkpoint_utils\n",
    "from utils.eval_utils import eval_step\n",
    "from tasks.mm_tasks.refcoco import RefcocoTask\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import wget"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04261d",
   "metadata": {
    "cellId": "du02z923qktvvrky05w3m",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f04261d",
    "outputId": "d25fa20e-10a2-45e2-e50b-8751a84785ff"
   },
   "outputs": [],
   "source": [
    "# Register refcoco task\n",
    "tasks.register_task('refcoco', RefcocoTask)\n",
    "\n",
    "# turn on cuda if GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use fp16 only when GPU is available\n",
    "use_fp16 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c466d9",
   "metadata": {
    "cellId": "fnnlq6f4nlh8794q2p7zce",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_id": "56a8484b-9bbe-49ee-afe7-0d801c21cdfb",
    "id": "66c466d9",
    "outputId": "d5b4fd0f-9628-4e69-e153-75dac85fb818"
   },
   "outputs": [],
   "source": [
    "# Load pretrained ckpt & config\n",
    "overrides={\"bpe_dir\":\"utils/BPE\"}\n",
    "models, cfg, task = checkpoint_utils.load_model_ensemble_and_task(\n",
    "        utils.split_paths('checkpoints/refcocog.pt'),\n",
    "        arg_overrides=overrides\n",
    "    )\n",
    "\n",
    "cfg.common.seed = 7\n",
    "\n",
    "# Fix seed for stochastic decoding\n",
    "if cfg.common.seed is not None and not cfg.generation.no_seed_provided:\n",
    "    np.random.seed(cfg.common.seed)\n",
    "    utils.set_torch_seed(cfg.common.seed)\n",
    "\n",
    "# Move models to GPU\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    if use_fp16:\n",
    "        model.half()\n",
    "    if use_cuda and not cfg.distributed_training.pipeline_model_parallel:\n",
    "        model.cuda()\n",
    "    model.prepare_for_inference_(cfg)\n",
    "\n",
    "# Initialize generator\n",
    "generator = task.build_generator(models, cfg.generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92535588",
   "metadata": {
    "cellId": "netr0ke7wtf1wbt4eu5uk1",
    "execution_id": "0ad0f020-a4af-49eb-882f-6d098874e821",
    "id": "92535588"
   },
   "outputs": [],
   "source": [
    "# Image transform\n",
    "from torchvision import transforms\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "patch_resize_transform = transforms.Compose([\n",
    "    lambda image: image.convert(\"RGB\"),\n",
    "    transforms.Resize((cfg.task.patch_image_size, cfg.task.patch_image_size), interpolation=Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "# Text preprocess\n",
    "bos_item = torch.LongTensor([task.src_dict.bos()])\n",
    "eos_item = torch.LongTensor([task.src_dict.eos()])\n",
    "pad_idx = task.src_dict.pad()\n",
    "def encode_text(text, length=None, append_bos=False, append_eos=False):\n",
    "    s = task.tgt_dict.encode_line(\n",
    "        line=task.bpe.encode(text.lower()),\n",
    "        add_if_not_exist=False,\n",
    "        append_eos=False\n",
    "    ).long()\n",
    "    if length is not None:\n",
    "        s = s[:length]\n",
    "    if append_bos:\n",
    "        s = torch.cat([bos_item, s])\n",
    "    if append_eos:\n",
    "        s = torch.cat([s, eos_item])\n",
    "    return s\n",
    "\n",
    "# Construct input for refcoco task\n",
    "patch_image_size = cfg.task.patch_image_size\n",
    "def construct_sample(image: Image, text: str):\n",
    "    w, h = image.size\n",
    "    w_resize_ratio = torch.tensor(patch_image_size / w).unsqueeze(0)\n",
    "    h_resize_ratio = torch.tensor(patch_image_size / h).unsqueeze(0)\n",
    "    patch_image = patch_resize_transform(image).unsqueeze(0)\n",
    "    patch_mask = torch.tensor([True])\n",
    "    src_text = encode_text(' which region does the text \" {} \" describe?'.format(text), append_bos=True, append_eos=True).unsqueeze(0)\n",
    "    src_length = torch.LongTensor([s.ne(pad_idx).long().sum() for s in src_text])\n",
    "    sample = {\n",
    "        \"id\":np.array(['42']),\n",
    "        \"net_input\": {\n",
    "            \"src_tokens\": src_text,\n",
    "            \"src_lengths\": src_length,\n",
    "            \"patch_images\": patch_image,\n",
    "            \"patch_masks\": patch_mask,\n",
    "        },\n",
    "        \"w_resize_ratios\": w_resize_ratio,\n",
    "        \"h_resize_ratios\": h_resize_ratio,\n",
    "        \"region_coords\": torch.randn(1, 4)\n",
    "    }\n",
    "    return sample\n",
    "  \n",
    "# Function to turn FP32 to FP16\n",
    "def apply_half(t):\n",
    "    if t.dtype is torch.float32:\n",
    "        return t.to(dtype=torch.half)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8da4a65",
   "metadata": {
    "cellId": "bqdel95y5lf32z4huqgb9",
    "execution_id": "45866840-9d19-4ccf-adad-674ec481de01",
    "id": "a8da4a65"
   },
   "outputs": [],
   "source": [
    "def get_iou(bb1, bb2):\n",
    "    # Taken from https://stackoverflow.com/a/42874377\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bb1 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    bb2 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x, y) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        in [0, 1]\n",
    "    \"\"\"\n",
    "    assert bb1['x1'] < bb1['x2']\n",
    "    assert bb1['y1'] < bb1['y2']\n",
    "    assert bb2['x1'] < bb2['x2']\n",
    "    assert bb2['y1'] < bb2['y2']\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9nip8KUHRtsE",
   "metadata": {
    "id": "9nip8KUHRtsE"
   },
   "outputs": [],
   "source": [
    "vqa_answers = pd.read_csv('../vqa_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rR-5za5gRfVX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rR-5za5gRfVX",
    "outputId": "488958a1-323b-4538-e118-57e2e4c4aac1"
   },
   "outputs": [],
   "source": [
    "os.mkdir('../imgs/')\n",
    "img_paths = Parallel(\n",
    "    n_jobs=100)(delayed(wget.download)(img_url, out='../imgs') for img_url in tqdm(vqa_answers.image)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d498e8",
   "metadata": {
    "cellId": "fwms6tbtb5vwa779ts5lt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution_id": "0b00943d-9f5e-4c16-9c91-6193d45e45b4",
    "id": "50d498e8",
    "outputId": "f3a6ffca-202e-4815-fbf3-0ca6a263cacb"
   },
   "outputs": [],
   "source": [
    "bounding_boxes = []\n",
    "sum_iou = 0\n",
    "n = 0\n",
    "progress = tqdm(vqa_answers.iterrows(), total=len(vqa_answers))\n",
    "for _, row in progress:\n",
    "    image_path = row['image'].split('/')[-1]\n",
    "    image = Image.open(os.path.join('../imgs', image_path))\n",
    "    text = row['answer']\n",
    "\n",
    "    # Construct input sample & preprocess for GPU if cuda available\n",
    "    sample = construct_sample(image, text)\n",
    "    sample = utils.move_to_cuda(sample) if use_cuda else sample\n",
    "    sample = utils.apply_to_sample(apply_half, sample) if use_fp16 else sample\n",
    "\n",
    "    # Run eval step for open-domain VQA\n",
    "    with torch.no_grad():\n",
    "        result, scores = eval_step(task, generator, models, sample)\n",
    "            \n",
    "    pred_box = [int(x) for x in result[0][\"box\"]]\n",
    "    bounding_boxes.append(pred_box)\n",
    "    gt_box = [row[key] for key in ('left', 'top', 'right', 'bottom')]\n",
    "    iou = get_iou(\n",
    "        {'x1': gt_box[0], 'y1': gt_box[1], 'x2': gt_box[2], 'y2': gt_box[3]},\n",
    "        {'x1': pred_box[0], 'y1': pred_box[1], 'x2': pred_box[2], 'y2': pred_box[3]}\n",
    "    )\n",
    "    sum_iou += iou\n",
    "    n += 1\n",
    "    avg_iou = sum_iou / n * 100\n",
    "    progress.set_description(f'IoU: {round(avg_iou, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17878564",
   "metadata": {
    "cellId": "o0gi1pyfhnmivjjitcwee",
    "execution_id": "f6d6dc7b-08fb-451a-b054-f2253c17c46d",
    "id": "17878564"
   },
   "outputs": [],
   "source": [
    "vqa_answers['pred_left'] = [x[0] for x in bounding_boxes]\n",
    "vqa_answers['pred_top'] = [x[1] for x in bounding_boxes]\n",
    "vqa_answers['pred_right'] = [x[2] for x in bounding_boxes]\n",
    "vqa_answers['pred_bottom'] = [x[3] for x in bounding_boxes]\n",
    "image_grounding = vqa_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b10a284",
   "metadata": {
    "cellId": "1sisbt9rmvarxjbwol8os",
    "execution_id": "e028aec0-3b9e-4cdb-8a48-038bf0578cc5",
    "id": "4b10a284"
   },
   "outputs": [],
   "source": [
    "image_grounding.to_csv('../ofa_image_grounding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crsJkTcKUVgv",
   "metadata": {
    "id": "crsJkTcKUVgv"
   },
   "source": [
    "# SAM re-annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's improve tightness of rectangles with [SAM](https://github.com/facebookresearch/segment-anything):\n",
    "1. Give SAM bounding box as a prompt\n",
    "2. Get object mask as a result\n",
    "3. Transform mask to bounding box"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download model and install necessary packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QartQPc1UYLY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QartQPc1UYLY",
    "outputId": "457c2990-ea71-4ff7-c148-be17be0f7426"
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pHzzfp2NUb8K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHzzfp2NUb8K",
    "outputId": "17538749-2242-4f2a-bcff-794fec2dbe85"
   },
   "outputs": [],
   "source": [
    "!wget \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XbutsL3RUe9N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbutsL3RUe9N",
    "outputId": "84898662-2a2d-470c-d716-72eca2d18b58"
   },
   "outputs": [],
   "source": [
    "!pip -q install git+https://github.com/facebookresearch/segment-anything.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BoAU5IpzUgsx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BoAU5IpzUgsx",
    "outputId": "2dbf9d00-b635-446e-98d2-56813751a80c"
   },
   "outputs": [],
   "source": [
    "!pip -q install opencv-python pycocotools matplotlib onnxruntime onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OuG1ElgOUi0F",
   "metadata": {
    "id": "OuG1ElgOUi0F"
   },
   "outputs": [],
   "source": [
    "def get_bounding_box(mask):\n",
    "    \"\"\"\n",
    "    Get the bounding box of a segmentation mask in the form of a NumPy bool array.\n",
    "    \n",
    "    Args:\n",
    "        mask (NumPy array): The segmentation mask as a NumPy bool array.\n",
    "        \n",
    "    Returns:\n",
    "        A NumPy array of the bounding box in the format [left, top, right, bottom].\n",
    "    \"\"\"\n",
    "    \n",
    "    rows = np.any(mask, axis=1)\n",
    "    cols = np.any(mask, axis=0)\n",
    "    left, right = np.where(cols)[0][[0, -1]]\n",
    "    top, bottom = np.where(rows)[0][[0, -1]]\n",
    "    \n",
    "    return np.array([left, top, right, bottom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W4oShv4hUkFM",
   "metadata": {
    "id": "W4oShv4hUkFM"
   },
   "outputs": [],
   "source": [
    "def get_image_array(url):\n",
    "    response = requests.get(url)\n",
    "    img_bytes = BytesIO(response.content)\n",
    "    img_cv2 = cv2.imdecode(np.frombuffer(img_bytes.read(), np.uint8), -1)\n",
    "    img_np = np.asarray(img_cv2)\n",
    "    return img_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g2Y40dDuUmOl",
   "metadata": {
    "id": "g2Y40dDuUmOl"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "id": "Tc9PKEkXUoFW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "09487b9aa4d24d2c8950a8308b1ef4a3",
      "7a31ef49ace8480aad8ad8d12bb06070",
      "7887fa78c9d84bd09c9fa73d69bb71b1",
      "d44996558028464aa5e11265f2f49493",
      "7c62c24fca9640598ce0a62fbe97ba1a",
      "a33e2a34bcba4191af29628843e9ab03",
      "ea4e00c2e99040a58e6eef3ee24e721e",
      "5b6996a361264a6db6b004a60d9216c2",
      "89826f04dc5b424084313bbf4dd27104",
      "325d30cfe5c049749d213f1c31cd58bf",
      "6dc98f8a5e05420296c0e72de10f9f55"
     ]
    },
    "id": "Tc9PKEkXUoFW",
    "outputId": "7c53fc2c-d66a-4eb6-bef0-8e3357c03ee9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "predictions = []\n",
    "sum_iou = 0\n",
    "n = 0\n",
    "progress = tqdm(image_grounding.iterrows(), total=len(image_grounding))\n",
    "for _, row in progress:\n",
    "    url = row['image']\n",
    "    input_box = np.array([row['pred_left'], row['pred_top'], row['pred_right'], row['pred_bottom']])\n",
    "    gt_box = np.array([row['left'], row['top'], row['right'], row['bottom']])\n",
    "\n",
    "    image = get_image_array(url)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "    predictor.set_image(image)\n",
    "\n",
    "    masks, _, _ = predictor.predict(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        box=input_box[None, :],\n",
    "        multimask_output=False,\n",
    "    )\n",
    "\n",
    "    predicted_box = get_bounding_box(masks[0])\n",
    "    iou = get_iou(\n",
    "        {'x1': gt_box[0], 'y1': gt_box[1], 'x2': gt_box[2], 'y2': gt_box[3]},\n",
    "        {'x1': predicted_box[0], 'y1': predicted_box[1], 'x2': predicted_box[2], 'y2': predicted_box[3]}\n",
    "    )\n",
    "    predictions.append([url] + list(predicted_box))\n",
    "    sum_iou += iou\n",
    "    n += 1\n",
    "    avg_iou = sum_iou / n\n",
    "    progress.set_description(f'IoU: {round(avg_iou, 2) * 100}')\n",
    "predictions = pd.DataFrame(predictions, columns=['image', 'left', 'top', 'right', 'bottom'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, let's at the results and save them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JjFRnlA3VFff",
   "metadata": {
    "id": "JjFRnlA3VFff"
   },
   "outputs": [],
   "source": [
    "predictions.to_csv('ofa_sam_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "notebookId": "5f49b9b6-9615-4c9f-8570-e684c2c6d3f2",
  "notebookPath": "OFA/image_grounding.ipynb",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09487b9aa4d24d2c8950a8308b1ef4a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7a31ef49ace8480aad8ad8d12bb06070",
       "IPY_MODEL_7887fa78c9d84bd09c9fa73d69bb71b1",
       "IPY_MODEL_d44996558028464aa5e11265f2f49493"
      ],
      "layout": "IPY_MODEL_7c62c24fca9640598ce0a62fbe97ba1a"
     }
    },
    "325d30cfe5c049749d213f1c31cd58bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b6996a361264a6db6b004a60d9216c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dc98f8a5e05420296c0e72de10f9f55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7887fa78c9d84bd09c9fa73d69bb71b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b6996a361264a6db6b004a60d9216c2",
      "max": 600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89826f04dc5b424084313bbf4dd27104",
      "value": 600
     }
    },
    "7a31ef49ace8480aad8ad8d12bb06070": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a33e2a34bcba4191af29628843e9ab03",
      "placeholder": "​",
      "style": "IPY_MODEL_ea4e00c2e99040a58e6eef3ee24e721e",
      "value": "IoU: 40.0: 100%"
     }
    },
    "7c62c24fca9640598ce0a62fbe97ba1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89826f04dc5b424084313bbf4dd27104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a33e2a34bcba4191af29628843e9ab03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d44996558028464aa5e11265f2f49493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_325d30cfe5c049749d213f1c31cd58bf",
      "placeholder": "​",
      "style": "IPY_MODEL_6dc98f8a5e05420296c0e72de10f9f55",
      "value": " 600/600 [29:49&lt;00:00,  3.25s/it]"
     }
    },
    "ea4e00c2e99040a58e6eef3ee24e721e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}